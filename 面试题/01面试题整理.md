# Redis 与数据库一致性（延迟双删及时间精度问题）
Redis 与数据库一致性问题主要出现在更新场景。
常见做法是“延迟双删”：更新数据库后，删除缓存，再延迟一段时间后再删除一次缓存。这样可以避免缓存被写回旧值的问题。
延迟时间需要结合业务来调优，一般设置为几百毫秒到 1 秒左右。
缺点是性能有损耗，而且不能保证绝对一致。
在实际生产中，还会结合 MQ 异步删除、Binlog 订阅等方式来提升一致性。

🔹 1. 为什么会有一致性问题？

典型场景：

系统里用 Redis 做缓存，MySQL 做持久化。
更新流程是：先更新数据库，再删缓存。

问题：
如果两个请求同时操作，可能出现 脏数据。

例子：
线程 A：更新数据库 -> 删除缓存
线程 B：读请求 -> 缓存里 miss -> 读数据库（还没更新） -> 写入缓存（旧值）
👉 结果：缓存里有旧值，数据库里是新值，不一致。
2. 延迟双删策略
核心思路：在更新数据库后，不只删一次缓存，而是删两次。
流程
更新数据库
删除缓存
等待一小段时间（比如 500ms）
再删除缓存一次
伪代码：
updateDB();
redis.del(key);
Thread.sleep(500); // 等待
redis.del(key);

🔹 3. 为什么要延迟？

因为可能在 第一次删缓存之后、数据库更新完成之前，有读请求进来，把旧数据查出来写回缓存。

延迟一段时间再删一次，确保这种“脏写回”的数据被清掉。
4. 时间精度问题

延迟多久合适？

过短：还没等到写缓存完成，第二次删就执行了，依旧可能残留脏数据。

过长：影响性能，缓存空窗期变长。

常见处理：

延迟时间一般设置为 业务平均读写耗时 + 波动时间，比如 500ms ~ 1s。

可以根据实际压测来调整。
5. 缺点

多一次 Redis 操作，开销大一些。

并不是 100% 保证一致性（比如网络抖动）。
🔹 6. 其他常见一致性方案

除了延迟双删，面试时也会问到替代方案：

先删缓存，再更新数据库

问题：删除后如果数据库更新失败，缓存和数据库会不一致。

消息队列保证最终一致性

更新数据库后，投递一条消息，异步删除缓存，失败可重试。

读请求加互斥锁（Cache Aside + 分布式锁）

避免多个线程同时回源数据库。

异步刷新缓存（订阅 Binlog）

比如用 Canal 订阅 MySQL binlog，自动更新缓存。

保证最终一致性，适合高并发场景。

# java线程池参数 
Java 线程池有 7 个关键参数：核心线程数、最大线程数、存活时间、时间单位、任务队列、线程工厂和拒绝策略。执行流程是：先用核心线程处理，队列满了再扩展线程，超过最大线程数就触发拒绝策略。常见优化点在于合理设置核心线程数和队列大小，

# java多线程 
Thread：最简单，但扩展性差。
Runnable：无返回值，推荐。

Callable：有返回值，适合需要计算结果的场景。

线程池：生产环境常用，避免频繁创建销毁线程，性能更好。

#  ArrayList vs LinkedList
ArrayList 底层是动态数组，LinkedList 底层是双向链表。
查询：ArrayList 快（O(1)），LinkedList 慢（O(n)）
增删：ArrayList 尾部添加快，中间慢；LinkedList 插入/删除节点快
内存：ArrayList 连续存储占用少，LinkedList 节点指针额外占内存
适用场景：ArrayList 随机访问频繁，LinkedList 插入删除频繁

1. 底层数据结构
类名	底层实现
ArrayList	动态数组（连续内存空间）
LinkedList	双向链表（节点包含前驱、后驱指针）
2. 查询效率（get / set）
ArrayList：O(1)
因为数组可以通过索引直接访问元素。
LinkedList：O(n)
需要从头/尾节点遍历到目标位置。
3. 增删效率（add / remove）
ArrayList：
尾部添加：O(1)（摊销）
中间插入/删除：O(n)，因为需要移动后续元素
LinkedList：
插入/删除节点：O(1)，只需修改前后指针
查找节点：O(n)，需要先遍历到该位置
4. 内存开销
ArrayList：
元素连续存储，内存占用少，但扩容会有临时数组复制开销
LinkedList：
每个节点有额外的 前驱/后驱指针，占用更多内存
5. 常用场景
ArrayList	随机访问频繁、增删主要在末尾、内存敏感
LinkedList	插入/删除操作频繁、中间操作多、不关心随机访问
6. 特殊方法
LinkedList 同时实现了 List + Deque，支持：
队列操作：addFirst(), addLast(), removeFirst(), removeLast()
栈操作：push(), pop()
ArrayList 仅实现 List 接口

# HashMap 扩容机制
HashMap 底层是数组+链表/红黑树，当元素数量超过 capacity * loadFactor 时触发扩容。
扩容机制是：数组容量翻倍，然后重新计算每个元素的索引并迁移到新数组中。
Java 8 对链表超过 8 个节点会转红黑树，并在扩容时保持树或链表结构。
扩容是耗时操作，也不是线程安全的，在多线程环境要注意使用 ConcurrentHashMap。

红黑树（Red-Black Tree）是一种 自平衡二叉搜索树（Self-Balancing Binary Search Tree），
它在插入、删除操作后通过颜色标记和旋转保持近似平衡，
从而保证 查找、插入、删除操作的时间复杂度为 O(log n)。


----------------------------------------------------------------------------------

1. HashMap 基本结构
底层：数组 + 链表（Java 8 后，当链表长度超过 8，会转成红黑树）
容量（capacity）：数组大小，必须是 2 的幂
负载因子（load factor）：默认 0.75
当元素数量超过 capacity * loadFactor 时，会触发扩容

2. 扩容触发条件
threshold = capacity * loadFactor
默认构造：capacity = 16, loadFactor = 0.75
阈值 threshold = 16 * 0.75 = 12
当 put 第 13 个元素时，会触发扩容

# 红黑树
红黑树（Red-Black Tree）是一种 自平衡二叉搜索树（Self-Balancing Binary Search Tree），它在插入、删除操作后通过颜色标记和旋转保持近似平衡，从而保证 查找、插入、删除操作的时间复杂度为 O(log n)。

🔹 红黑树的 5 条性质

每个节点是 红色 或 黑色

根节点是 黑色

每个叶子节点（NIL 空节点）是 黑色

如果一个节点是红色，则它的子节点必须是黑色（不能有连续两个红色节点）

从任一节点到其所有叶子节点的路径上，黑色节点数量相同

👉 这些性质确保树的高度不会过高，避免退化成链表。

🔹 为什么要用红黑树？

普通二叉搜索树在极端情况下可能退化成链表，导致查找变成 O(n)

红黑树通过 旋转（左旋/右旋）+ 变色 来维持平衡

平衡后树的高度接近 log₂n，从而保证 增删改查都高效

🔹 红黑树与 AVL 树区别
特点	红黑树	AVL 树
平衡性	较“松弛”的平衡	严格平衡
插入/删除	更快（旋转较少）	较慢（旋转多）
查找效率	稍差（树可能更高）	更好
应用场景	HashMap、TreeMap、Linux 内核	高度查询频繁场景

应用
Java HashMap（链表长度超过 8 时，转为红黑树，提高查询效率）
TreeMap / TreeSet（基于红黑树实现有序性）
Linux 内核调度、内存管理

# 消息队列中的顺序问题
常见消息队列选型对比
MQ 中间件	顺序支持情况	吞吐量	延迟	特点/适用场景
Kafka	分区内有序；分区间无序	极高	毫秒级	大数据日志、实时流计算，吞吐量第一
RocketMQ	分区内有序；支持顺序消费（MessageQueueSelector）	高	毫秒级	金融、电商订单，天然支持顺序消息
RabbitMQ	Queue 内部 FIFO，有序	中等	低（微秒-毫秒）	灵活路由、事务性强，适合微服务
ActiveMQ	支持顺序，但性能较弱	低	较低	老牌 MQ，适合小规模系统
Pulsar	分区内有序；支持 Key_Shared 消费模型	高	毫秒级	云原生、分布式、多租户

# java1.8的垃圾回收机制
Java 1.8 使用 分代收集策略：新生代（复制算法，Minor GC）、老年代（标记整理，Major GC），默认收集器是 Parallel Scavenge + Parallel Old，引入了 G1 收集器和 Metaspace，优化了大内存和类加载的问题。

# 常用注册中心的区别
常见的注册中心主要有 Eureka、Zookeeper、Consul、Nacos 等，它们的作用都是 服务注册与发现，但在架构设计、CAP 取舍、功能扩展等方面有明显区别。下面帮你整理一个对比表，方便快速理解。

1. 常见注册中心的对比
注册中心	CAP 取舍	一致性模型	健康检查方式	多语言支持	生态/特点
Eureka (Netflix)	AP 优先	最终一致性	Client 心跳机制	Java 为主	Spring Cloud Netflix 默认方案（现已停更，进入维护）
Zookeeper	CP 优先	强一致性（ZAB 协议）	长连接 + 会话机制（临时节点）	跨语言较好	原本是分布式协调工具，注册发现只是副作用，性能一般
Consul (HashiCorp)	CP 优先	Raft 协议保证一致性	主动探测（HTTP/TCP/脚本）	多语言友好（HTTP API）	除注册发现外，还提供 KV 存储、服务配置、分布式锁
Nacos (阿里开源)	CP & AP 模式可切换	Raft 保证一致性（CP） / 最终一致性（AP）	支持 Client 心跳和主动探测	多语言	除注册中心外，还内置 配置中心、动态 DNS，与 Spring Cloud、Dubbo 集成度高
2. 核心差别总结

CAP 取舍

Eureka 偏向 AP（高可用，允许短时间不一致）

Zookeeper、Consul 偏向 CP（保证一致性，可能降低可用性）

Nacos 可以在 CP 和 AP 模式间切换

健康检查

Eureka：客户端自己上报心跳

Zookeeper：利用临时节点 + Session

Consul：主动健康检查（HTTP/TCP/自定义脚本）

Nacos：支持心跳 + 主动探测，比较灵活

功能丰富度

Zookeeper：强一致分布式协调

Consul：服务注册、配置、KV 存储、服务网格支持

Nacos：注册发现 + 配置中心（适合微服务场景）

Eureka：轻量，已逐渐被 Nacos/Consul 替代

3. 适用场景

Eureka：老的 Spring Cloud 项目

Zookeeper：Hadoop、Kafka 等强一致场景，或分布式锁协调

Consul：需要多语言支持 + 健康检查严格 + 配置存储

Nacos：Java/微服务体系，尤其是 Spring Cloud Alibaba、Dubbo

# vue mvvm 工作原理
Vue 初始化时，把 data 转换成响应式对象（通过 Proxy 代理）。

模板编译时，Vue 会把用到的数据和视图节点建立依赖关系（Watcher）。

当数据（Model）变化时，触发依赖更新，自动渲染对应的 DOM（View）。

如果用户在界面上操作（输入、点击），通过 v-model、事件监听把变化同步到 Model。


# 常用配置中心的区别
在分布式系统里，配置中心（Configuration Center）是核心组件，主要用来集中管理配置、动态刷新配置、保证配置一致性。
常用的有：Spring Cloud Config、Apollo、Nacos、Disconf、Etcd/Consul 等。下面我帮你梳理下它们的区别。

🔑 常用配置中心对比
配置中心	特点	优势	劣势	适用场景
Spring Cloud Config	基于 Git 的配置中心，Spring Cloud 体系原生支持	配合 Spring Cloud 生态无缝集成；版本管理好（基于 Git）	依赖 Git，实时性差（需刷新）；功能较单一	传统 Spring Cloud 项目，配置变更不频繁
Apollo（携程开源）	支持多环境、多集群配置管理，实时推送（长轮询），权限管理完善	UI 友好；灰度发布；客户端缓存；热更新；支持多语言	需要额外部署服务，架构较复杂	大中型企业，配置多、频繁修改，需权限审计
Nacos（阿里开源）	集注册中心 + 配置中心 + 服务管理一体化	功能全面；天然支持 Spring Cloud Alibaba；动态刷新；支持监听	相对重，早期版本稳定性不足	微服务项目（Spring Cloud Alibaba / Dubbo）
Disconf（百度开源）	早期分布式配置管理，支持动态推送	支持注解方式；配置热加载	更新慢，社区活跃度低，逐渐被替代	老项目，仍在使用 Disconf 的环境
Consul（HashiCorp）	主要是服务发现 + KV 存储，可做配置中心	一体化服务治理（健康检查、KV 存储、DNS）	界面和管理不如 Apollo/Nacos 友好	跨语言系统，需要服务发现 + 配置中心
Etcd（CoreOS/K8s 使用）	强一致性的分布式 KV 存储，K8s 默认依赖	高可用；支持 watch 实时更新；性能强	仅是 KV 存储，缺少 UI 和权限管理	Kubernetes、云原生场景，作为底层存储

# spring cloud的优势
Spring Cloud 是微服务架构中最常用的框架之一，它的优势主要体现在 快速构建、生态完整、与 Spring Boot 无缝集成。我帮你整理成几个方面：
生态完善，一站式解决方案

提供 全家桶式微服务组件：

服务注册发现（Eureka / Nacos）

配置中心（Spring Cloud Config / Nacos）

服务网关（Spring Cloud Gateway / Zuul）

负载均衡（Ribbon / Spring Cloud LoadBalancer）

熔断限流（Hystrix / Resilience4j）

分布式链路追踪（Sleuth + Zipkin）

几乎覆盖了微服务需要的所有基础设施，开箱即用。

2. 与 Spring Boot 无缝集成

基于 Spring Boot 自动装配，只需要少量配置即可接入。

使用门槛低，Spring 开发者很快上手。

3. 社区活跃、文档齐全

Spring 生态全球最活跃的 Java 社区之一，更新频繁，遇到问题容易找到解决方案。

官方与企业级文档、教程、最佳实践丰富。

4. 灵活的组件选型

可以按需组合不同的子项目，不是强绑定：

服务发现可以用 Eureka / Nacos / Consul

配置中心可以用 Config / Apollo / Nacos

熔断可以用 Hystrix / Resilience4j / Sentinel
👉 不会像某些框架那样强耦合。

5. 微服务治理能力强

提供了 服务治理、配置管理、熔断限流、日志追踪 等常见功能。

降低了企业自建微服务基础设施的成本。

6. 云原生和容器化支持

与 Kubernetes、Docker 等无缝集成，Spring Cloud Alibaba 还提供了与阿里云服务的深度对接。

适合云原生应用的快速迁移和扩展。


# redis
 读写锁,持久化的两种rdb,缓存击穿，穿透，雪崩。分布式锁，
 ## 缓存雪崩
 定义：缓存雪崩是指系统中的缓存同时失效（或者缓存服务挂掉），导致大量的请求直接访问数据库，给数据库带来巨大的压力，可能会导致数据库宕机或性能瓶颈。
原因：缓存失效时间相同：如果大量缓存的过期时间设置相同，且缓存服务不可用时，所有请求都会直接打到数据库，导致瞬间大量的数据库请求。
缓存服务器宕机：缓存服务器本身出现故障，导致所有缓存无法访问。
解决方案：缓存过期时间随机化：为不同的缓存设置不同的过期时间，避免所有缓存同时失效。例如，通过在过期时间基础上加一个随机值。
long expireTime = baseExpireTime + (Math.random() * randomFactor);
使用多级缓存：采用本地缓存（如 Guava）和分布式缓存（如 Redis）的结合，当一级缓存失效时可以尝试从二级缓存中获取数据，减轻数据库的负载。
增加缓存的过期时间：合理设置缓存的过期时间，避免频繁的缓存更新带来过大的数据库压力。
降级处理：当缓存不可用时，应用可以暂时关闭缓存，或者使用熔断器（如 Hystrix）来防止大量请求打到数据库。
## 缓存穿透 (Cache Penetration)

定义：缓存穿透是指查询的数据在缓存和数据库中都不存在，导致每次请求都会访问数据库，形成缓存穿透。攻击者通常通过构造恶意请求，使得每次请求都绕过缓存直接查询数据库。
原因：请求的数据在数据库和缓存中都不存在，导致每次请求都直接查询数据库，增加数据库的压力。
常见的如恶意用户通过构造无效的请求（如非法 ID 或不存在的记录）来绕过缓存查询数据库。
解决方案：缓存空对象：当缓存查询不到数据时，可以将 "空值"（如 null 或特殊的标记值）存入缓存，并为其设置短期的过期时间，这样相同的无效请求会被缓存，避免每次都查询数据库。
cache.set("key", null, CACHE_NULL_TTL);
使用布隆过滤器：布隆过滤器是一种空间效率极高的数据结构，可以用来判断某个请求是否存在于数据库中。通过布隆过滤器预先过滤掉无效请求，避免请求到达数据库。
if (!bloomFilter.mightContain(queryKey)) {
    return;  // 请求数据不存在，直接返回
}
校验参数合法性：在应用层加验证，对传入的请求参数进行合法性检查（如 ID 是否存在、格式是否正确），从源头上减少不必要的查询。
## 缓存击穿 (Cache Breakdown)

定义：缓存击穿是指某个热点数据的缓存失效，而在该数据频繁被访问时，由于缓存失效，所有请求都会直接访问数据库，导致数据库瞬间承受巨大的压力。不同于缓存雪崩，缓存击穿通常是由于单个热点数据的缓存失效引起的。

原因：热点数据的缓存失效：某些数据在业务中非常常见，缓存失效后所有请求会集中到数据库，导致数据库压力增大。

数据过期或未及时更新：热点数据在缓存中失效后，多个请求会同时去访问数据库，给数据库带来压力。

解决方案：加锁机制：使用互斥锁（如 mutex、Redis 中的 SETNX）确保只有第一个请求会去加载数据，其他请求可以等待第一个请求完成后，直接从缓存中获取数据。

if (lock.acquireLock("hotspotKey")) {
    // Load data from DB and set cache
} else {
    // Wait for lock to release, then get from cache
}


使用双重检查机制：为了避免缓存击穿带来的性能问题，可以使用双重检查机制。首先检查缓存，如果缓存失效，则加锁进行数据加载，再次检查缓存是否已经被其他线程填充。

if (cache.contains(key)) {
    return cache.get(key);
}

synchronized (key) {
    if (!cache.contains(key)) {
        // Load data from DB and set cache
    }
}


提前预加载缓存：可以在缓存失效前，提前预加载热点数据缓存，确保热点数据的高可用性，避免高并发请求时造成数据库负担。
# spring cloud
nacos: 发现与注册实现原理
    1. 服务注册原理（Provider → Nacos）
    是通过客户端（如 Spring Cloud）将服务信息注册到 Nacos Server，再由客户端或网关从 Nacos 获取服务列表并做负载均衡调用的。
    服务启动时，客户端 SDK（如 Spring Cloud Nacos）自动将服务的元数据注册到 Nacos,
    Nacos Server 会把这些信息保存在内存中，并持久化到磁盘或数据库.
    2. 服务健康检查 
    默认使用 客户端心跳机制（主动续租）客户端每隔 5 秒向 Nacos 发送心跳（HTTP）若超过 15 秒无心跳，Nacos 将其标记为不健康 .若超过 30 秒，服务实例将被剔除（仅对临时实例
    3. 服务发现原理（Consumer ← Nacos）
    消费者（如 Spring Cloud 或 Dubbo 客户端）通过 Nacos SDK 查询服务列表.namingService.getAllInstances("product-service");
    Nacos 会返回该服务名下的所有健康实例（IP+Port）
    客户端本地缓存一份服务列表（推+拉结合）
    后续客户端通过负载均衡策略（如 Ribbon、LoadBalancer）从这些实例中选择一个发起请求。

load banlance:
    Ribbon 是 Spring Cloud 最早使用的客户端负载均衡组件，由 Netflix 提供，现在已被弃用。
        客户端负载均衡 = 请求发送前，客户端决定调用哪个服务实例
    LoadBalancer 是 Spring Cloud 官方自研的 轻量级、模块化客户端负载均衡器，是 Ribbon 的接班人。更现代、原生支持 Reactor、WebFlux、Gateway与 Spring Boot 集成更紧密（比如 WebClient）支持自动注册、扩展能力强
    算法： 轮询、随机、权重

Sentinel:是阿里巴巴开源的流量防卫兵，支持服务级、接口级、热点参数等多种限流方式
spring boot: 自动装配实现原理，

# arraylist 的add set 实现原理
初始化：默认构造函数new ArrayList<>()并不会立刻分配数组空间，而是等第一次添加元素时再分配（懒加载）：建议直接指定容量 new ArrayList<>(10);
添加元素（add）：自动扩容机制！默认扩容为原容量的 1.5 倍，扩容会复制整个数组，性能代价高，所以 频繁扩容性能差，建议初始化容量足够大。
访问元素（get / set）：直接使用下标访问，底层是数组，因此时间复杂度是 O(1)没有边界检查会抛出 IndexOutOfBoundsException
删除元素（remove）：删除后要将后面的元素整体向前移动，时间复杂度 O(n)
# hashmap的实现原理
它结合了 数组、链表、红黑树 和 哈希算法，在查找、插入、删除操作上提供了 接近 O(1) 的性能。
HashMap 由一个数组 + 链表 + 红黑树组成。
每个数组槽位（bucket） 对应一个 hash 值相同的节点链表或红黑树。
从 JDK 1.8 起，当链表长度超过 8 且数组长度大于 64，链表会转为红黑树，提高查找效率。
插入（put）过程: 1. 步骤一：计算 hash 值(使用 key 的 hashCode() 方法，结合扰动函数（spread）生成最终 hash)
    2.定位数组索引（bucket）index = (n - 1) & hash;
    3.处理冲突（哈希冲突）如果该 bucket（槽位）为空，直接放入；如果不为空，说明发生冲突，需要链表或红黑树处理：如果 key 已存在：覆盖旧值；否则插入到链表末尾；
    4.判断是否需要扩容 如果实际元素数量超过负载因子（默认 0.75） × 当前容量，就会触发扩容。如果链表长度超过阈值（8），转为红黑树。
查询（get）过程:1. 先用 key.hashCode() 算出 hash，确定数组下标；2. 在对应的链表/红黑树中遍历：比较 hash 值；再比较 equals() 确认 key 是否相等；3.找到后返回对应的 value。
扩容机制（resize）:当 HashMap 中的元素个数超过阈值时，会触发 resize,新数组大小是原数组的 2 倍,所有旧数据需要重新哈希计算位置，再插入新数组.
为什么链表会转为红黑树？:链表查询是 O(n)，而红黑树是 O(log n)，当 hash 冲突严重时（同一槽位很多 key），查询效率会下降。JDK 1.8 为了解决这一问题，引入了 树化机制：
    链表长度 > 8 且数组容量 ≥ 64：转为红黑树;链表长度 < 6：从树退回链表
红黑树（Red-Black Tree）是一种自平衡的二叉搜索树（BST），它通过给每个节点增加一个 颜色标记（红或黑），来确保整个树的高度在一定范围内，从而使得插入、删除、查找操作都能保持在 O(log n) 的时间复杂度。
# mysql 
读写锁，
索引的实现原理

# java

# k8s docker

# jvm
1. s0 ,s1转到老生代3
条件一：对象年龄达到阈值（默认15）

每当对象经历一次 Minor GC（即新生代垃圾回收），如果还存活，它的“年龄”就加1。

当对象在 Survivor 区 中存活的次数达到某个阈值（由 JVM 参数 MaxTenuringThreshold 控制，默认是 15），对象就会被移动到老生代。
-XX:MaxTenuringThreshold=15
条件二：Survivor 区空间不足时，直接进入老生代
如果 Survivor 区空间不足以容纳所有需要复制的存活对象，那么 JVM 会将一部分对象直接晋升到老生代。

这种情况下，不管对象的年龄是多少，只要 Survivor 区空间放不下，就会 提前晋升到老生代。
条件三：大对象直接进入老生代（与 S 区无关，但相关）

大对象如果超过一定阈值，可能会直接分配到老生代（绕过 Eden/S 区）。这受参数控制：
-XX:PretenureSizeThreshold
Young Generation:
├── Eden 区     (新对象大多先分配在这里)
├── Survivor 0 区（S0） ←→ Survivor 1 区（S1）

2. 

# redis 
锁，原子性，分布式锁，redission
